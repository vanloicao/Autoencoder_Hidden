{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano as th\n",
    "from theano import tensor as T\n",
    "from numpy import random as rng\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define identify activation function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Definition Autoencoder class</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(BaseEstimator):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size = 6,\n",
    "                 n_epochs=100,\n",
    "                 mini_batch_size=20,\n",
    "                 learning_rate=0.1,\n",
    "                 K = 1.0):\n",
    "\n",
    "        #Steepness parameter k for logistic function Sigmoid_ex\n",
    "        self.K = K\n",
    "        #Input_size is the same number of the input dimension, int.\n",
    "        self.input_size = input_size\n",
    "        #Hidden_size is the number of neurons in the hidden layer, int.\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        \n",
    "        #Create random seed for randomly generate Weight matrix\n",
    "        rng.seed(0)\n",
    "        initial_W = np.asarray(rng.uniform(\n",
    "                 low=-4 * np.sqrt(6. / (self.hidden_size + self.input_size)),\n",
    "                 high=4 * np.sqrt(6. / (self.hidden_size + self.input_size)),\n",
    "                 size=(self.input_size, self.hidden_size)), dtype=th.config.floatX)\n",
    "\n",
    "        self.W = th.shared(value=initial_W, name='W', borrow=True)\n",
    "        self.b1 = th.shared(name='b1', value=np.zeros(shape=(self.hidden_size,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        self.b2 = th.shared(name='b2', value=np.zeros(shape=(self.input_size,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        \n",
    "        self.n_epochs = n_epochs\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "    \n",
    "    #%% Sigmoid function with steepness parameter K\n",
    "    def sigmoid_ex(self,x):\n",
    "        return 1.0/(1.0 + T.exp(-self.K*x))\n",
    "        #%% Fit data, define cost function and compute grad\n",
    "        \n",
    "        \n",
    "    #Optimizing loss function    \n",
    "    def fit(self, X):\n",
    "        self.activation_function = self.sigmoid_ex   #hidden activation = sigmoid\n",
    "        self.output_function = identity              #output activation = identity\n",
    "\n",
    "        #X is an numpy matrix, rows and cols correspond to datapoints and features.\n",
    "        #assert type(X) is np.ndarray\n",
    "        assert len(X.shape)==2\n",
    "        self.X = X                #Training set\n",
    "        self.X = th.shared(name='X', value=np.asarray(self.X,\n",
    "                         dtype=th.config.floatX),borrow=True)\n",
    "        # Wrap data in theano variable which is to get this to run fast on the gpu.\n",
    "        self.n = X.shape[1]    #Dimension\n",
    "        self.m = X.shape[0]    #Size of data\n",
    "\n",
    "        \"****************** Compute hidden and output data *******************\"\n",
    "        index = T.lscalar()\n",
    "        x=T.matrix('x')\n",
    "        \n",
    "        params = [self.W, self.b1, self.b2]  #List of parameters\n",
    "        #Hidden data\n",
    "        hidden = self.activation_function(T.dot(x, self.W)+self.b1)\n",
    "        #Reconstruction data at output layer\n",
    "        output = self.output_function(T.dot(hidden, T.transpose(self.W))+self.b2)\n",
    "\n",
    "        \"********************** Define cost function *************************\"\n",
    "        \"Use cross-entropy loss, suitable for binary data\"\n",
    "        #L = -T.sum(x*T.log(output) + (1-x)*T.log(1-output), axis=1)\n",
    "        #cost=T.mean(L)\n",
    "\n",
    "        \"MEAN-MSE is used in this work, for real-value data\"\n",
    "        cost = (((x - output)**2).mean(1)).mean()\n",
    "\n",
    "\n",
    "        \"*********** Update cost ******************\"\n",
    "        updates=[]\n",
    "        #Return gradient with respect to W, b1, b2.\n",
    "        gparams = T.grad(cost,params)\n",
    "\n",
    "        \"======ADAGRAD is used in this work =======\"\n",
    "        eps  = 1e-8\n",
    "        accugrads = [th.shared(name='accugrad', value=np.zeros(shape=param.shape.eval(),\n",
    "                            dtype=th.config.floatX),borrow=True) for param in params]\n",
    "        # compute list of weights updates\n",
    "        updates = OrderedDict()\n",
    "        for accugrad, param, gparam in zip(accugrads, params, gparams):\n",
    "            # c.f. Algorithm 1 in the Adadelta paper (Zeiler 2012)\n",
    "            agrad = accugrad + gparam * gparam\n",
    "            updates[param] = param - (self.learning_rate /(T.sqrt(agrad) + eps)) * gparam\n",
    "            updates[accugrad] = agrad\n",
    "        \"===========================================\"\n",
    "        \n",
    "        \n",
    "        fit = th.function(inputs=[index],\n",
    "                          outputs=[cost],\n",
    "                          updates=updates,\n",
    "                          givens={x:self.X[index:index+self.mini_batch_size,:]})\n",
    "        \n",
    "        re = 0  #reconstruction error after each epoch\n",
    "        RE = [] #An array storing all re during training process\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for row in range(0,self.m, self.mini_batch_size):\n",
    "                re_batch = fit(row)\n",
    "                re = re + re_batch[0]\n",
    "                \n",
    "            re = re/self.n_epochs   \n",
    "            RE = np.append(RE, re)\n",
    "            #print(re)\n",
    "        RE = np.reshape(RE, (-1,1))    \n",
    "        return RE\n",
    "    \n",
    "    \n",
    "    #%% Get data from hidden layer\n",
    "    def get_hidden(self,data):\n",
    "        x=T.dmatrix('x')\n",
    "        hidden = self.activation_function(T.dot(x,self.W)+self.b1)\n",
    "        transformed_data = th.function(inputs=[x], outputs=[hidden])\n",
    "        return transformed_data(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #%% Get data from the output layer\n",
    "    def get_output(self,data):\n",
    "        x = T.dmatrix('x')\n",
    "        hidden = self.activation_function(T.dot(x, self.W)+self.b1)\n",
    "        output = self.output_function(T.dot(hidden,T.transpose(self.W))+self.b2)\n",
    "        transformed_data = th.function(inputs = [x], outputs = [output])\n",
    "        return transformed_data(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #%% Get parameter values\n",
    "    def get_weights(self):\n",
    "        return [self.W.get_value(), self.b1.get_value(), self.b2.get_value()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Data(dataset):\n",
    "    if (dataset == \"WBC\"):\n",
    "        d = np.genfromtxt(\"data/wobc.csv\", delimiter=\",\")\n",
    "        label_threshold = 2\n",
    "        # 9 attributes + 1 class[2 - benign(458); 4 - malignant(241)]\n",
    "    elif (dataset == \"WDBC\"):\n",
    "        d = np.genfromtxt(\"data/wdbc.csv\", delimiter=\",\")\n",
    "        label_threshold = 2\n",
    "        # 30 attributes + 1 class [2 - benign(357); 4 - malignant(212)]\n",
    "    elif (dataset == \"C-heart\"):\n",
    "        d = np.genfromtxt(\"data/C-heart.csv\", delimiter=\",\")\n",
    "        label_threshold = 0\n",
    "        # 13 attributes + 1 class [0 - Level0(164); level 1,2,3,4 - (139), 6 missing)\n",
    "    elif (dataset == \"ACA\"):\n",
    "        d = np.genfromtxt(\"data/australian.csv\", delimiter=\",\")\n",
    "        #Australia: 14 feature + 1 class [ 0 - 383, 1 - 307]\n",
    "        label_threshold = 0\n",
    "    else:\n",
    "        print(\"No dataset is chosen\")\n",
    "\n",
    "    \"*************************Chosing dataset*********************************\"\n",
    "\n",
    "    # discard the '?' values in wdbc\n",
    "    d = d[~np.isnan(d).any(axis=1)]\n",
    "\n",
    "    # shuffle\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(d)\n",
    "\n",
    "    dX = d[:,0:-1]      # discard the first column (ids) and the last (labels)\n",
    "    dy = d[:,-1]\n",
    "\n",
    "    dy = dy >label_threshold   # dataset 1-(2,4), 2-(2,4), 3-(0,1,2,3,4), 4-(0, 1)\n",
    "\n",
    "    # separate into normal and anomaly\n",
    "    dX0 = dX[~dy]   # Normal data\n",
    "    dX1 = dX[dy]    # Anomaly data\n",
    "    dy0 = dy[~dy]   # Normal label\n",
    "    dy1 = dy[dy]    # Anomaly label\n",
    "\n",
    "    split = 0.8    #split 70% for training and 30% for testing\n",
    "    idx  = int(split * len(dX0))\n",
    "    idx1 = int(split* len(dX1))\n",
    "    # train_X contains only normal examples\n",
    "    train_X = dX0[:idx]\n",
    "\n",
    "    # test set is 30% of the normal class and 30% of anomaly class\n",
    "    test_X = np.concatenate((dX0[idx:], dX1[idx1:]))  # 30% of normal and 30% anomal data\n",
    "    test_y = np.concatenate((dy0[idx:], dy1[idx1:]))  # 30% of normal and 30% anomal labels\n",
    "\n",
    "    print(\"Normal: %d, Test normal: %d, Test anomaly: %d\" %(len(train_X), len(dX0)-len(train_X), len(dX1) - idx1))\n",
    "    \"\"\"We consider normal class and anomaly class are positive class and negative class\n",
    "    espectively. Thus, we put true label equal 1 for normal and 0 for anomly examples\n",
    "    in testing set. The roc_curve function will calculate FPR and TPR based on moving\n",
    "    a threshold from high prediction values to low prediction values\"\"\"\n",
    "    test_y = (~test_y).astype(np.int)\n",
    "\n",
    "    return train_X, test_X, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Plot RE curce</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotting_RE(RE, ymin, ymax):\n",
    "    \"\"\"Plotting RE during training process\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.title('RE on training', fontsize=16)\n",
    "\n",
    "    x = np.indices((len(RE),1))\n",
    "    \n",
    "    plt.xlim([0.0, len(RE) + 1.0])\n",
    "    plt.ylim([ymin,ymax])\n",
    "\n",
    "    plt.plot(x[0], RE,  'b', label = 'Recon error')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('RE', fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training Autoencode</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 355, Test normal: 89, Test anomaly: 48\n",
      "[[ 0.47547411  0.43118054  0.40241388  0.38106091  0.3638887   0.34947302\n",
      "   0.33703866  0.3261088   0.31636604  0.30758698  0.29960766  0.29230381\n",
      "   0.28557873  0.27935555  0.27357203  0.26817695  0.2631276   0.25838788\n",
      "   0.25392701  0.24971845  0.24573917  0.24196903  0.23839034  0.23498746\n",
      "   0.23174652  0.22865515  0.22570232  0.2228781   0.22017359  0.21758072\n",
      "   0.21509221  0.21270144  0.21040238  0.20818954  0.20605786  0.20400274\n",
      "   0.20201993  0.2001055   0.19825585  0.19646763  0.19473774  0.19306329\n",
      "   0.1914416   0.18987016  0.18834665  0.18686888  0.18543481  0.18404252\n",
      "   0.1826902   0.18137617  0.18009882  0.17885667  0.17764828  0.17647232\n",
      "   0.17532753  0.1742127   0.17312669  0.17206844  0.17103692  0.17003116\n",
      "   0.16905023  0.16809326  0.1671594   0.16624787  0.16535789  0.16448875\n",
      "   0.16363975  0.16281024  0.16199956  0.16120713  0.16043236  0.1596747\n",
      "   0.15893361  0.15820858  0.15749912  0.15680477  0.15612507  0.15545958\n",
      "   0.1548079   0.15416962  0.15354435  0.15293173  0.1523314   0.15174301\n",
      "   0.15116623  0.15060074  0.15004623  0.14950241  0.14896899  0.1484457\n",
      "   0.14793225  0.14742841  0.14693391  0.14644852  0.145972    0.14550412\n",
      "   0.14504468  0.14459346  0.14415024  0.14371485]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAADmCAYAAADGIbLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcFNW5//HPw7AM+y4urN6ggoigI4IxQcUFY0SMEIkRweWCMQSzx2guiSQmuSGLEslCDCKiQSRG+UV/weW6X1QGJciigrgwgIDAoOzbc/841UzT9Mw0s1TPTH/fr1e9upZTVc8UzTxT55w6Ze6OiIhIeeplOwAREakdlDBERCQjShgiIpIRJQwREcmIEoaIiGRECUNERDKihCFZY2ajzcyTpj1m9q6Z/dzM8lPKnpNSNnVqla2fI4qvlZn9xMxOq4Zjd41+xtEV2DdxjbtWdVySe+pnOwARYDhQBDQHLgd+GM1/I03Z8cCCNOs/rbboMtMK+DHh53i9io+9DhgAvFuBfR+P9l1XpRFJTlLCkJpgkbuvjOafMrPuwPVmdrO7H0gpu9zdX4k5vipnZo3cfXcmZaNyFfqZ3X0jsLEi+4qkUpWU1ESvA42BdlV1QDM7xsxmmNnHZrbbzBab2dUpZRLVN/3N7AEz+8TM1prZ5NQqspT9ugLvRYt/SaomGx1tf87MXjKzS83sDTPbDdwUbRtnZvPNbLOZFZvZK2Z2SerxU6ukzGy6mRWZWV8ze9HMdpjZCjO7sZSfqWvSuvfNbKaZjTCz5Wa23cwKzezsND/bzVH5XWb2mpmdFS1PL/+qS12jhCE1UVdgK7ApzbZ6ZlY/Zcor62Bm1hR4HrgYuBUYCrwJ3G9mY9Lscj+h+udLwB+BrxOqyUqzLioL8AtCFdAAQnVQwgnAZOD3wEXAM0k/6z2EarkrgULgn2Z2cVk/U6QF8CAwE7iMUFX3RzM7N4N9Pwd8B/iv6Lx50XkPtgWZ2Q3AncDT0fGnR+fLanuRZJG7a9KUlQkYDThwIqF6tDVwHbAPGJdS9pyobLppSTnnGReVOydl/dPABiAvJZ7bU8r9E3innHN0jfa9Ic2254ADQJ9yjlEvug5PAo+lOfbopHXTo3XnJq1rBHwMTE1zjbsmrXsf2AK0TlpXEJW7KimW1cATKTF+KSo3PdvfH03xT2rDkJrgrZTlP7j73aWU/TrwWsq6neUc//PAGnd/LmX9TOBeoCfhjiPh8ZRybwLnl3OO8rzv7otSV5rZ6cDtwBlAe8CiTW9ncMwd7v5sYsHdd5vZCqBzBvvOd/ctScuJnz+xb8dompCy32OEhC45SAlDaoLLCb2L2gPfBm4ys1fdfUaasu+4e+ERHr8N6XsJfZS0PdnmlOXdhL/eK+Ow85tZJ0LV1DJCj7APCb+Mfwr0yOCYW9Ks2w2U2t6S5JCfMUo2JO17TPS5IaXcfjP7OIPjSx2khCE1wRKPekmZ2f8Ai4FJZvZ3d99eBcffTKj2SnV09JmuraSqpXuPwGCgJfBldy9KrDSzJjHEU55EgjsqeWXUXlRlnRGkdlGjt9QoHrqQfo/wi+qmKjrs80BHM/tsyvqrCH9BL6+CcyS6yDY+gn0SiWFvYoWZnQCkxpkNRdE0PGX9UPSHZs7SP7zUOO4+18wWAN81s7vdPbmNooeZbUuz25tl3I1MB24GHjGz2wi/CL8KXACMdff9VRD2esKdyggzWwxsB95z97LuXp4mVEHNMLPfEKqBbidUTWX1jzl3P2BmtxO6Cd8DPAwcD9xC6MGW+nyM5ADdYUhN9SPCXcaNKesnA/PTTKXW+UeJZCCh99EvCQ23pwIj3X1qVQTr4QHDGwg9vZ4mdHG9tJx9lhISVxdgLvB9wi/kF6oipspy93uAbxES62PA9YR4nZA0JMeYu17RKiKZMbMzCL3UrnH3+7Mdj8RLCUNE0jKzboRuzC8CnxDu4m4F9gC93H1HFsOTLIi1SsrMBpvZ22a20sxuKaXMl81smZktNbMH44xPRA6xE+gF/IVQnfcTQnXZOUoWuSm2O4yoO947hPrQIkId71fcfVlSme7AbOA8d99iZke5+4a0BxQRkVjFeYfRD1jp7qvcfQ8wizA+TbL/BKYknkBVshARqTniTBjHEcamSSiK1iU7ATjBzF6ORu0cHFt0IiJSpjifw7A061Lrw+oD3QkDzXUEXjSzXu5efMiBwgijYwCaNm16+kknnVT10YqI1GELFy782N3bH8k+cSaMIqBT0nJHYG2aMq+4+17gPTN7m5BADnnDWtR3fipAQUGBFxYe6dBCIiK5zcw+ONJ94qySWgB0N7NuZtYQGEF4WCnZo8C5AGbWjlBFtSrGGEVEpBSxJQx330d4L8E8wtg9s919qZlNNLMhUbF5wCYzWwY8C3yvnKEVREQkJrX+wT1VSYmIHDkzW+juBUeyjwYfFJFY7N27l6KiInbt2pXtUHJKfn4+HTt2pEGDBpU+lhKGiMSiqKiI5s2b07VrV6KXNUk1c3c2bdpEUVER3bp1q/TxNFqtiMRi165dtG3bVskiRmZG27Ztq+yuTglDRGKjZBG/qrzmShgikjPy8vLo06cPvXr14tJLL6W4uLj8neQgJQwRyRmNGzdm0aJFLFmyhDZt2jBlypRsh1Sq/fv3l7lcmn379lVHOIAShojkqAEDBrBmzZqDy5MmTeKMM86gd+/e/PjHPz64fsaMGfTu3ZtTTz2VkSNHAvDBBx8waNAgevfuzaBBg/jwww8BGD16NOPHj+ess87i+OOPZ86cOWnPPXPmTPr160efPn0YO3bswWTQrFkzJkyYwJlnnsn8+fPp2rUrEydO5Oyzz+bhhx9m0aJF9O/fn969e3P55ZezZcsWAM455xxuvfVWBg4cyF133VUt1wvUS0pEsuCb34RFi6r2mH36wJ13ZlZ2//79PPPMM1x//fUAPPnkk6xYsYLXXnsNd2fIkCG88MILtG3bljvuuIOXX36Zdu3asXnzZgDGjRvHNddcw6hRo5g2bRrjx4/n0UcfBWDdunW89NJLvPXWWwwZMoRhw4Ydcu7ly5fz0EMP8fLLL9OgQQNuuukmHnjgAa655hq2b99Or169mDhx4sHy+fn5vPTSSwD07t2b3//+9wwcOJAJEyZw++23c2f0QxcXF/P8889X6hqWRwlDRHLGzp076dOnD++//z6nn346F1xwARASxpNPPknfvn0B2LZtGytWrODf//43w4YNo127dgC0adMGgPnz5/PII48AMHLkSL7//e8fPMfQoUOpV68ePXv2ZP369YfF8Mwzz7Bw4ULOOOOMgzEdddRRQGhjueKKKw4pf+WVVwKwdetWiouLGThwIACjRo1i+PDhh5WrTkoYIhK7TO8EqlqiDWPr1q188YtfZMqUKYwfPx5354c//CFjx449pPzkyZMz6mWUXKZRo0YH59ONpOHujBo1il/84heHbcvPzycvL++QdU2bNi33/EdSrjLUhiEiOadly5ZMnjyZX//61+zdu5eLLrqIadOmsW3bNgDWrFnDhg0bGDRoELNnz2bTpjCkXaJK6qyzzmLWrFkAPPDAA5x99tkZn3vQoEHMmTOHDRs2HDzmBx+UP3Bsy5Ytad26NS+++CIA999//8G7jbjoDkNEclLfvn059dRTmTVrFiNHjmT58uUMGDAACI3PM2fO5OSTT+a2225j4MCB5OXl0bdvX6ZPn87kyZO57rrrmDRpEu3bt+fee+/N+Lw9e/bkZz/7GRdeeCEHDhygQYMGTJkyhS5dupS773333ceNN97Ijh07OP7444/ovFVBgw+KSCyWL19Ojx49sh1GTkp37Ssy+KCqpEREJCNKGCIikhElDBERyYgShojEpra3mdZGVXnNlTBEJBb5+fls2rRJSSNGifdh5OfnV8nxYu1Wa2aDgbuAPOAed/9lyvbRwCQgMcDL3e5+T5wxikj16NixI0VFRWzcuDHboeSUxBv3qkJsCcPM8oApwAVAEbDAzOa6+7KUog+5+7i44hKReDRo0KBK3vom2RNnlVQ/YKW7r3L3PcAs4LIYzy8iIpUQZ8I4DlidtFwUrUt1hZktNrM5ZtYpntBERKQ8cSaMdCN4pbZ+/T+gq7v3Bp4G7kt7ILMxZlZoZoWqDxURiUecCaMISL5j6AisTS7g7pvcfXe0+Bfg9HQHcvep7l7g7gXt27evlmBFRORQcSaMBUB3M+tmZg2BEcDc5AJmdkzS4hBgeYzxiYhIGWLrJeXu+8xsHDCP0K12mrsvNbOJQKG7zwXGm9kQYB+wGRgdV3wiIlI2jVYrIpKDcnK02p07sx2BiEhuqPUJY9WqbEcgIpIban3C2LULVq8uv5yIiFROrU8YAE89le0IRETqvlqfMBo0gHnzsh2FiEjdV+sTRosW8PTTsH9/tiMREanb6kTC2LwZFi7MdiQiInVbnUgYZvDkk9mORESkbqv1CaN+fTjtNLVjiIhUt1qfMAAuugjmz4etW7MdiYhI3VUnEsaFF4ZG72efzXYkIiJ1V51IGAMGQLNmqpYSEalOdSJhNGwI556rhm8RkepUJxIGhHaMVatgyZJsRyIiUjfVmYTx5S9Do0bwhz9kOxIRkbqpziSM9u1hxAiYMUO9pUREqkOdSRgA3/gGbN8O06dnOxIRkbqnTiWM00+H/v1hyhQ4cCDb0YiI1C11KmFAuMtYsUI9pkREqlqsCcPMBpvZ22a20sxuKaPcMDNzMzui980CDBsGHTrA3XdXLlYRETlUbAnDzPKAKcDFQE/gK2bWM0255sB44NWKnKdhQxg7Fp54At59tzIRi4hIsjjvMPoBK919lbvvAWYBl6Up91PgV8Cuip5o7NgwKOEdd1T0CCIikirOhHEckPz27aJo3UFm1hfo5O7/LOtAZjbGzArNrHDjxo2HbT/2WBg/PvSWev31ygcuIiLxJgxLs84PbjSrB/wO+E55B3L3qe5e4O4F7du3T1vmRz+Ctm3hW98C97RFRETkCMSZMIqATknLHYG1ScvNgV7Ac2b2PtAfmFuRhm+AVq3gpz+FF16ARx6pYMQiInJQnAljAdDdzLqZWUNgBDA3sdHdt7p7O3fv6u5dgVeAIe5eWNET3nAD9OoF3/se7Kpwi4iIiECMCcPd9wHjgHnAcmC2uy81s4lmNqQ6zlm/Ptx5J7z3XvgUEZGKM6/lFfwFBQVeWFj2Tcjll8O//gWFhXDyyTEFJiJSg5nZQnc/oir/Ovekdzp/+hM0bw5XXQW7d2c7GhGR2iknEkaHDnDvvbB4Mdx6a7ajERGpnXIiYQBccgl8/evw29/CU09lOxoRkdonZxIGwKRJ0KMHjBoF69ZlOxoRkdolpxJG48YwaxZ88gkMGQI7dmQ7IhGR2iOnEgZA797w4IOwcGG409B7M0REMpNzCQPC3cWkSTBnDvzXf2U7GhGR2qF+tgPIlm9/G95+G37+c+jcOYxwKyIipcvZhGEWXuW6Zg3ceGN4j8a112Y7KhGRmisnq6QSGjSAv/8dLrwQrr8e7r8/2xGJiNRcOZ0wAPLz4dFH4bzzYPRomDkz2xGJiNRMOZ8wIHS3nTsXBg6EkSPhd7/LdkQiIjWPEkakSZPwHvArrggN4t/9rrrciogkU8JIkp8PDz0UhhD5zW/g6qv1Hg0RkYSc7SVVmrw8+P3vw3vBb7sNVqwIb+zr1Kn8fUVE6jLdYaRhFka1/cc/wrMap58Ozz+f7ahERLIro4RhZj83syZJy18ws8ZJyy3MbEZ1BJhNQ4fCq69CmzZw/vnwq1+pXUNEclemdxg/AJolLc8Cjklabgx8taqCqkl69AhJ47LL4Ac/CM9srF2b7ahEROKXacKwcpYzO4jZYDN728xWmtktabbfaGZvmtkiM3vJzHpW5DxVrWVLePhh+MtfYP78MIDhP/6R7ahEROIVWxuGmeUBU4CLgZ7AV9IkhAfd/RR37wP8CvhtXPGVxwxuuAFefx26dIEvfQmuvBI2bMh2ZCIi8Yiz0bsfsNLdV7n7HkK11mXJBdz9k6TFpoDHGF9GTjwRXnkFfvaz8IR4z57wwAPgNS5SEZGqdSTdam80s21J+11vZpui5eYZ7H8csDppuQg4M7WQmX0d+DbQEDgv3YHMbAwwBqBz584ZBV+VGjQIXW6HDoXrrgvPa/z1r6E77sknxx6OiEgszDP409jM3ieDv/bdvVsZxxgOXOTuN0TLI4F+7v6NUspfFZUfVdY5CwoKvLCwsLzQqs3+/TB1akggn34KN98c3rHRsmXWQhIRKZeZLXT3giPZJ6MqKXfv6u7dypqAz5dzmCIg+fG3jkBZ/Y1mAUMziS+b8vLga18Lz2uMHh2eEP/MZ8Ldxp492Y5ORKTqVLoNw8yONrO7gXfKKboA6G5m3cysITACmJtyrO5Ji5cAKyobX1zatw+9qAoL4ZRTYPz4UD01e7ae3RCRuiHTB/damdkDZrbRzNaa2XgLfgysIrRFXFfWMdx9HzAOmAcsB2a7+1Izm2hmQ6Ji48xsqZktIrRjlFkdVROdfjo88wz885/hpUxXXgl9+4YGcjWMi0htlmkbxh+AS4GHgMFAD+AJQk+m2909awNnZLsNoyz794fBDH/ykzAmVd++YciRyy8PVVkiItlSbW0YhOqha939u8AQwoN777r7edlMFjVdXh5cdRUsWwbTp8P27TB8eOiKO20a7N6d7QhFRDKXacI4FlgG4O6rgF3AX6orqLqmfn0YNSokjtmzw7s3rr8+PAD405/Cxo3ZjlBEpHyZJox6wN6k5f3AjqoPp27Lywt3GK+/Dk8+CaedBhMmQOfO4XmOhQuzHaGISOkybcM4ADwFJCpRLgaeJyVpuPsQYlaT2zAysXw53HVXeJf49u3Qr1/opjt8ODRtmu3oRKSuqs42jPsIz0xsiqaZhKe2N6VMcoR69IA//QnWrAnPbnz6KVx7LRxzDIwdC6+9pt5VIlIzZHSHUZPV9juMVO7w8stwzz2hvWPnTjjpJLjmGvjqV0P1lYhIZVXnHYbExAzOPjv0qlq3Dv78Z2jXLnTH7doVBg4MdyRqKBeRuClh1GAtW8KYMfDii/Duu3D77SFRfO1rocrqoovC0+VKHiISB1VJ1TLu8Oab8Le/hZc6vfsu1KsX7jyGDg1vBuzSJdtRikhNV5EqKSWMWswdFi+GOXPgkUfCcx4Ap54Kl14Kl1wCZ5yhp8pF5HBKGDluxQqYOxceewz+93/D0CTt2sHgwWG64AI46qhsRykiNYEShhy0eTPMmwePPx4+P/44rD/tNDj//JA8PvtZaNw4u3GKSHYoYUhaBw7AG2/Av/4VnjCfPx/27oVGjWDAADj33DD16xfWiUjdp4QhGdm2LfS8euopeO45WLQotIfk50P//vD5z8PnPhfmmzXLdrQiUh2UMKRCNm+GF14omd54I9yV5OWFBvSzzw53IgMGhAcHzbIdsYhUlhKGVIlPPgmN5i+/HKZXX4Ud0ahhRx8d7jz69YMzz4SCAmjRIrvxisiRq0jCqF9dwUjt1aJFSc8qCO0db74Z2j7mzw/jWz36aEn5E08MiaOgILxxsE8faN48O7GLSPXRHYZUyObNsGBBSB4LF4b5tWvDNjM44YTwhsE+fUqmDh2yG7OIlKjxVVJmNhi4C8gD7nH3X6Zs/zZwA7AP2Ahc5+4flHVMJYyaY+3a0P7x+utheuMN+CDpX69DB+jdO7SLnHIK9OoV3j6Yn5+9mEVyVY1OGGaWB7wDXAAUAQuAr7j7sqQy5wKvuvsOM/sacI67X1nWcZUwarYtW0IvrEWLwlPpixfD0qUlr6etVw8+8xk4+eSSqUePUM2lRCJSfWp6G0Y/YGX0ilfMbBZwGdGrXwHc/dmk8q8AV8cYn1SD1q1LnvNI2LcPVq6EJUtC28iSJSGJPPZY6J0FIZF06xaSx0knlSSRE04IT6+rp5ZI/OJMGMcRXrqUUAScWUb564H/n26DmY0BxgB01gsiap369UMSOOkkGDasZP2uXfDOO+EthMuWhc+33grPiyTuSCAkoRNOCFP37odO6rElUn3iTBjp/iZMWx9mZlcDBcDAdNvdfSowFUKVVFUFKNmVnx/aOHr3PnT9/v3w/vvw9tshoSQ+n30W7r//0LLt28N//Mfh0/HHhy7BujMRqbg4E0YR0ClpuSPhta+HMLPzgduAge6+O3W75J68vJJf/F/4wqHbduwIQ7yvXBkGX1yxIiy/+CI8+OChr7fNzw8voerWrWTq2jVMXbqoqkukPHEmjAVAdzPrBqwBRgBXJRcws77An4HB7r4hxtiklmrSJPS4OuWUw7ft3h3uTFatKpneey+smz8fiosPP1bnziF5dO5cMnXqFKaOHdUQL7kttoTh7vvMbBwwj9Ctdpq7LzWziUChu88FJgHNgIct/Kn3obsPiStGqVsaNQoN5SeemH57cXHo9vvee+EzeXrjDdiQ5k+Wo44KiaNjx5IkctxxJZ/HHqvxt6Tu0oN7IqXYuRNWry6ZPvwQiorCtHp1+Ey9S4HQ8H7ssSUJ5Nhjwyt1jzkmzB99dJhv2jT+n0kkoaZ3qxWpVRo3LumNVZrt22HNmsOndevC5wsvhAca9+49fN/mzUPySJ46dCj57NAh3NF06KCqMKkZlDBEKqFp0/KTinsYSmXt2pBI1q2Djz4q+fzoo/BA47x5YeDHdFq0CMkjdWrfvmQ66qjQcN+uHTRsWD0/r+Q2JQyRamYGbduGKV3jfLJdu2D9+sOnjRtDm8r69aEX2Pz5YV3iQcdULVqEJJJIIG3bHj6fiCkxKclIeZQwRGqQ/PzQS6tLl/LLHjgQ7lw2bkw/bdoUXs27bl24g9m0qWSY+nSaNYM2bULyaNOmZGrd+vD51q1LpmbN1B05VyhhiNRS9eqV3DX06JHZPjt3hsSRSCaJ+U2bQvJJfG7eHJLMli1hft++0o+ZlwetWoXkke4zeWrZMkyJ+VatQrWeEk7toIQhkkMaNy7pFpwp9/Ba3y1bShJIYj4xFRcfOr96dcm63eU8fpuXF6rQEskkeT6xnFiXmG/RInQaSP5s3FiJp7opYYhImczCL+XmzcODjEdq1y7YujUkj61bQyIpLg7z6abi4tBledmyknVl3eEk5OUdmkRKm5o1O3w++TMxKQEdTglDRKpVfn6YKvoCLfdwl7J1K3z6aehJtnVr+EwsJ+YTy4n5Tz8N3Zu3bStZziT5QEgWTZsemkQSy02blkyp65s0OXR7Ykpe36hR7UxGShgiUqOZVT7pJNu9uyR5bNtWMiUvf/ppeMYmeT6xvGVLuANKLG/fHtqGjvRnSiSQJk1KpuTlxo0P3Za6vnHjQ+eT1yVP9epV/polKGGISE5p1ChM7dpV3TEPHAg90JITy/btYV3y+sR8us/E/Mcfl8zv3Fmybf/+isW2f3/VJQ0lDBGRSqpXr6Taqrrs3RsSx86dJckkkVCSP5PX79mjOwwRkZzToEFJz7FsqcLcIyIidZkShoiIZEQJQ0REMqKEISIiGVHCEBGRjChhiIhIRmJNGGY22MzeNrOVZnZLmu2fN7PXzWyfmQ2LMzYRESlbbAnDzPKAKcDFQE/gK2bWM6XYh8Bo4MG44hIRkczE+eBeP2Clu68CMLNZwGXAskQBd38/2lbKe8RERCRb4qySOg5YnbRcFK0TEZFaIM6EkW4wX6/QgczGmFmhmRVu3LixkmGJiEgm4kwYRUCnpOWOwNqKHMjdp7p7gbsXtG/fvkqCExGRssWZMBYA3c2sm5k1BEYAc2M8v4iIVEJsCcPd9wHjgHnAcmC2uy81s4lmNgTAzM4wsyJgOPBnM1saV3wiIlK2WIc3d/cngCdS1k1Iml9AqKoSEZEaRk96i4hIRpQwREQkI0oYIiKSESUMERHJiBKGiIhkRAlDREQyooQhIiIZUcIQEZGMKGGIiEhGlDBERCQjShgiIpIRJQwREcmIEoaIiGRECUNERDKihCEiIhlRwhARkYwoYYiISEaUMEREJCOxJgwzG2xmb5vZSjO7Jc32Rmb2ULT9VTPrGmd8IiJSutgShpnlAVOAi4GewFfMrGdKseuBLe7+GeB3wH/HFZ+IiJQtzjuMfsBKd1/l7nuAWcBlKWUuA+6L5ucAg8zMYoxRRERKEWfCOA5YnbRcFK1LW8bd9wFbgbaxRCciImWqH+O50t0peAXKYGZjgDHR4m4zW1LJ2OqCdsDH2Q6ihtC1CHQdAl2HEsnXosuR7hxnwigCOiUtdwTWllKmyMzqAy2BzakHcvepwFQAMyt094JqibgW0XUooWsR6DoEug4lKnst4qySWgB0N7NuZtYQGAHMTSkzFxgVzQ8D/sfdD7vDEBGR+MV2h+Hu+8xsHDAPyAOmuftSM5sIFLr7XOCvwP1mtpJwZzEirvhERKRscVZJ4e5PAE+krJuQNL8LGH6Eh51aBaHVBboOJXQtAl2HQNehRKWuhanGR0REMqGhQUREJCO1OmGUN9RIXWVmnczsWTNbbmZLzezmaH0bM3vKzFZEn62zHWsczCzPzN4ws39Gy92ioWVWREPNNMx2jNXNzFqZ2Rwzeyv6XgzI4e/Dt6L/F0vM7G9mlp8L3wkzm2ZmG5IfMyjtO2DB5Oh352IzOy2Tc9TahJHhUCN11T7gO+7eA+gPfD362W8BnnH37sAz0XIuuBlYnrT838DvouuwhTDkTF13F/Avdz8JOJVwPXLu+2BmxwHjgQJ370XoYDOC3PhOTAcGp6wr7TtwMdA9msYAf8zkBLU2YZDZUCN1kruvc/fXo/lPCb8cjuPQoVXuA4ZmJ8L4mFlH4BLgnmjZgPMIQ8tADlwHM2sBfJ7QyxB33+PuxeTg9yFSH2gcPcvVBFhHDnwn3P0FDn9urbTvwGXADA9eAVqZ2THlnaM2J4xMhhqp86IRffsCrwId3H0dhKQCHJW9yGJzJ/B94EC03BYojoaWgdz4XhwPbATujarm7jGzpuTg98Hd1wC/Bj4kJIqtwEJy7zuRUNp3oEK/P2tzwshoGJG6zMyaAX8Hvunun2Q7nriZ2ReBDe6+MHl1mqJ1/XtRHzgN+KO79wW2kwPVT+lEdfSXAd2AY4H7l4PMAAAETklEQVSmhOqXVHX9O1GeCv0/qc0JI5OhRuosM2tASBYPuPsj0er1idvK6HNDtuKLyWeBIWb2PqFK8jzCHUerqDoCcuN7UQQUufur0fIcQgLJte8DwPnAe+6+0d33Ao8AZ5F734mE0r4DFfr9WZsTRiZDjdRJUT39X4Hl7v7bpE3JQ6uMAh6LO7Y4ufsP3b2ju3cl/Pv/j7t/FXiWMLQM5MZ1+AhYbWYnRqsGAcvIse9D5EOgv5k1if6fJK5FTn0nkpT2HZgLXBP1luoPbE1UXZWlVj+4Z2ZfIPxFmRhq5I4shxQLMzsbeBF4k5K6+1sJ7Rizgc6E/zjD3f2wwRvrIjM7B/iuu3/RzI4n3HG0Ad4Arnb33dmMr7qZWR9Cw39DYBVwLeEPwpz7PpjZ7cCVhN6EbwA3EOrn6/R3wsz+BpxDGJF2PfBj4FHSfAeiZHo3oVfVDuBady8s9xy1OWGIiEh8anOVlIiIxEgJQ0REMqKEISIiGVHCEBGRjChhiIhIRpQwRLLMzNzMhpVfUiS7lDAkp5nZ9OgXdur0SrZjE6lpYn1Fq0gN9TQwMmXdnmwEIlKT6Q5DBHa7+0cp02Y4WF00zsweN7MdZvaBmV2dvLOZnWJmT5vZTjPbHN21tEwpM8rM3jSz3Wa23symp8TQxsweNrPtZrYqzTkmROfebWYfmdmM6rgQImVRwhAp3+2EsXf6AFOBGWZWAGBmTYB/AdsI72i5nDDY3bTEzmY2FvgzcC/QG/gCsDTlHBMI4/ycCjwETDOzLtH+VwDfBW4ivPDmi8Br1fBzipRJQ4NITov+0r8a2JWyaYq7/8DMHLjH3f8zaZ+ngY/c/Woz+0/C+xc6Ri+zSoxr9SzQ3d1XmlkRMNPd0w45Hp3jl+7+w2i5PvAJMMbdZ5rZt4GxQK9oBFaRrFAbhgi8QHhNZbLipPn5KdvmE97yB9ADWJxIFpH/JQwK2dPMPiEMfPdMOTEsTsy4+z4z20jJy24eJryG9j0zm0e4o5lb1wbPk5pPVVIisMPdV6ZMH2e4r1H6i2ec9C+qSSf1zsGJ/n+6+2rgRMJdxifAb4CF0Vv1RGKjhCFSvv5plpdH88uAU82sedL2swj/t5a7+3pgDeG9DBXm7rvc/XF3/xZwBnAy4QVSIrFRlZQINDKzo1PW7Xf3jdH8l8xsAfAc4SU8g4Azo20PEBrFZ5jZBKA1oYH7EXdfGZW5A/idma0HHgeaAIPc/TeZBGdmown/V18lNK5fSbgjWXGEP6dIpShhiITXeqa+bWwN4bWVAD8BrgAmAxsJL5tZAODuO8zsIsKLvF4jNJ4/RmhzICrzRzPbA3wH+G9gM/DEEcRXDPyA0LjegHBX8yV3f+8IjiFSaeolJVKGqAfTcHefk+1YRLJNbRgiIpIRJQwREcmIqqRERCQjusMQEZGMKGGIiEhGlDBERCQjShgiIpIRJQwREcmIEoaIiGTk/wBY7o/v2e3adAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, test_X, test_y = process_Data(\"WBC\")     \n",
    "\n",
    "#Normalize data using standard scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X_scale = scaler.transform(train_X)\n",
    "test_X_scale  = scaler.transform(test_X)\n",
    "\n",
    "\n",
    "input_size  = train_X_scale.shape[1]\n",
    "h_size      = (np.sqrt(input_size)).astype(np.int) + 1\n",
    "epoch       = 100\n",
    "l_rate      = 0.01\n",
    "k           = 1.0 \n",
    "\n",
    "\n",
    "#create an AE object\n",
    "AE = AutoEncoder(input_size          = input_size,\n",
    "                     hidden_size     = h_size,\n",
    "                     n_epochs        = epoch,\n",
    "                     learning_rate   = l_rate,\n",
    "                     K               = k)\n",
    "\n",
    "\n",
    "RE = AE.fit(train_X_scale)\n",
    "print(np.reshape(RE, (1,-1)))\n",
    "Plotting_RE(re, 0, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>BUild RE-based classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.993\n"
     ]
    }
   ],
   "source": [
    "#get reconstruction of train_X and test_X\n",
    "output_train  = AE.get_output(train_X_scale)\n",
    "output_test   = AE.get_output(test_X_scale)\n",
    "\n",
    "\n",
    "#*************** RE on each example *************\"\n",
    "RE_MSE = (((test_X - output_test[0])**2).mean(1))\n",
    "\n",
    "\"\"\"RE (MSE) between output and input is used as anomalous score.\n",
    "We put minus \"-\" to RE_MSE to for computing FPR and TPR using roc_curve\"\"\"\n",
    "\n",
    "predictions_auto = -RE_MSE\n",
    "FPR_ae, TPR_ae, thresholds_auto = roc_curve(actual, predictions_auto)\n",
    "auc_ae = auc(FPR_ae, TPR_ae)\n",
    "print('AUC: %0.3f' %auc_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>View hidden data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  9.97471694e-01,   6.31840466e-01,   2.27169507e-01,\n",
       "           4.39930227e-01],\n",
       "        [  1.05567409e-01,   1.81869694e-01,   5.98294382e-01,\n",
       "           1.36315074e-01],\n",
       "        [  3.15864019e-01,   5.50997146e-02,   7.45718965e-01,\n",
       "           2.72828647e-02],\n",
       "        ..., \n",
       "        [  8.22807772e-01,   1.73545157e-01,   9.68849142e-01,\n",
       "           4.15882249e-02],\n",
       "        [  3.28515508e-01,   7.22174854e-02,   8.12727617e-02,\n",
       "           9.99998838e-01],\n",
       "        [  6.43735239e-01,   9.83542410e-01,   2.26634330e-01,\n",
       "           9.28505195e-04]])]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get hidden data of train_X and test_X\n",
    "train_z  = AE.get_hidden(train_X_scale)\n",
    "test_z   = AE.get_hidden(test_X_scale)\n",
    "\n",
    "train_z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
